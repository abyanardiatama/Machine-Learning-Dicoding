{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "#Latihan Membuat Model Klasifikasi Gambar\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "  https://github.com/dicodingacademy/assets/raw/main/ml_pemula_academy/messy-vs-clean-room.zip \\\n",
    "  -O /tmp/messy_vs_clean_room.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan ekstraksi pada file zip\n",
    "import zipfile,os\n",
    "local_zip = '/Users/abyanardiatama/Downloads/messy-vs-clean-room.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/Users/abyanardiatama/Downloads')\n",
    "zip_ref.close()\n",
    "\n",
    "base_dir = '/Users/abyanardiatama/Downloads/images'\n",
    "train_dir = os.path.join(base_dir, '/Users/abyanardiatama/Downloads/images/images/train')\n",
    "validation_dir = os.path.join(base_dir, '/Users/abyanardiatama/Downloads/images/images/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['messy', 'clean']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/Users/abyanardiatama/Downloads/images/images/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'messy', 'clean']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/Users/abyanardiatama/Downloads/images/images/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=20,\n",
    "                    horizontal_flip=True,\n",
    "                    shear_range = 0.2,\n",
    "                    fill_mode = 'nearest')\n",
    " \n",
    "test_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # direktori data latih\n",
    "        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel\n",
    "        batch_size=4,\n",
    "        # karena ini merupakan masalah klasifikasi 2 kelas, gunakan class_mode = 'binary'\n",
    "        class_mode='binary')\n",
    " \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir, # direktori data validasi\n",
    "        target_size=(150, 150), # mengubah resolusi seluruh gambar menjadi 150x150 piksel\n",
    "        batch_size=4, # karena ini merupakan masalah klasifikasi 2 kelas gunakan class_mode = 'binary'\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 15:47:12.520632: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model dengan 'adam' optimizer loss function 'binary_crossentropy' \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 - 8s - loss: 0.7236 - accuracy: 0.5300 - val_loss: 0.6796 - val_accuracy: 0.5000 - 8s/epoch - 319ms/step\n",
      "Epoch 2/20\n",
      "25/25 - 6s - loss: 0.6935 - accuracy: 0.5400 - val_loss: 0.6296 - val_accuracy: 0.8000 - 6s/epoch - 248ms/step\n",
      "Epoch 3/20\n",
      "25/25 - 6s - loss: 0.6133 - accuracy: 0.6500 - val_loss: 1.7284 - val_accuracy: 0.5500 - 6s/epoch - 237ms/step\n",
      "Epoch 4/20\n",
      "25/25 - 6s - loss: 0.7072 - accuracy: 0.5000 - val_loss: 0.6833 - val_accuracy: 0.5500 - 6s/epoch - 235ms/step\n",
      "Epoch 5/20\n",
      "25/25 - 6s - loss: 0.6485 - accuracy: 0.6200 - val_loss: 0.5034 - val_accuracy: 0.8000 - 6s/epoch - 232ms/step\n",
      "Epoch 6/20\n",
      "25/25 - 6s - loss: 0.6471 - accuracy: 0.7300 - val_loss: 0.5120 - val_accuracy: 0.6500 - 6s/epoch - 227ms/step\n",
      "Epoch 7/20\n",
      "25/25 - 6s - loss: 0.6123 - accuracy: 0.7400 - val_loss: 0.5367 - val_accuracy: 0.6000 - 6s/epoch - 225ms/step\n",
      "Epoch 8/20\n",
      "25/25 - 6s - loss: 0.5432 - accuracy: 0.7400 - val_loss: 0.5711 - val_accuracy: 0.6000 - 6s/epoch - 227ms/step\n",
      "Epoch 9/20\n",
      "25/25 - 6s - loss: 0.5498 - accuracy: 0.6900 - val_loss: 0.4389 - val_accuracy: 0.9000 - 6s/epoch - 226ms/step\n",
      "Epoch 10/20\n",
      "25/25 - 6s - loss: 0.5297 - accuracy: 0.7200 - val_loss: 0.4395 - val_accuracy: 0.8000 - 6s/epoch - 253ms/step\n",
      "Epoch 11/20\n",
      "25/25 - 8s - loss: 0.5441 - accuracy: 0.7400 - val_loss: 0.5099 - val_accuracy: 0.7000 - 8s/epoch - 306ms/step\n",
      "Epoch 12/20\n",
      "25/25 - 6s - loss: 0.5097 - accuracy: 0.7700 - val_loss: 0.3937 - val_accuracy: 0.9000 - 6s/epoch - 223ms/step\n",
      "Epoch 13/20\n",
      "25/25 - 6s - loss: 0.5825 - accuracy: 0.7400 - val_loss: 0.4607 - val_accuracy: 0.8000 - 6s/epoch - 224ms/step\n",
      "Epoch 14/20\n",
      "25/25 - 7s - loss: 0.4913 - accuracy: 0.8300 - val_loss: 0.4375 - val_accuracy: 0.7500 - 7s/epoch - 263ms/step\n",
      "Epoch 15/20\n",
      "25/25 - 11s - loss: 0.4766 - accuracy: 0.8100 - val_loss: 0.3747 - val_accuracy: 0.8000 - 11s/epoch - 450ms/step\n",
      "Epoch 16/20\n",
      "25/25 - 13s - loss: 0.4439 - accuracy: 0.7900 - val_loss: 0.4062 - val_accuracy: 0.8000 - 13s/epoch - 518ms/step\n",
      "Epoch 17/20\n",
      "25/25 - 10s - loss: 0.5220 - accuracy: 0.8000 - val_loss: 0.5271 - val_accuracy: 0.7000 - 10s/epoch - 385ms/step\n",
      "Epoch 18/20\n",
      "25/25 - 10s - loss: 0.4525 - accuracy: 0.8200 - val_loss: 0.3970 - val_accuracy: 0.9000 - 10s/epoch - 408ms/step\n",
      "Epoch 19/20\n",
      "25/25 - 9s - loss: 0.5047 - accuracy: 0.7500 - val_loss: 0.4257 - val_accuracy: 0.9000 - 9s/epoch - 374ms/step\n",
      "Epoch 20/20\n",
      "25/25 - 10s - loss: 0.5136 - accuracy: 0.8000 - val_loss: 0.4455 - val_accuracy: 0.7500 - 10s/epoch - 414ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1298eb520>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# latih model dengan model.fit \n",
    "model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=25,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
    "      epochs=20, # tambahkan epochs jika akurasi model belum optimal\n",
    "      validation_data=validation_generator, # menampilkan akurasi pengujian data validasi\n",
    "      validation_steps=5,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/abyanardiatama/Downloads/Latihan Membuat Model Klasifikasi Gambar.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/abyanardiatama/Downloads/Latihan%20Membuat%20Model%20Klasifikasi%20Gambar.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/abyanardiatama/Downloads/Latihan%20Membuat%20Model%20Klasifikasi%20Gambar.ipynb#ch0000011?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m files\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/abyanardiatama/Downloads/Latihan%20Membuat%20Model%20Klasifikasi%20Gambar.ipynb#ch0000011?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m image\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/abyanardiatama/Downloads/Latihan%20Membuat%20Model%20Klasifikasi%20Gambar.ipynb#ch0000011?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    " \n",
    "uploaded = files.upload()\n",
    " \n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path = fn\n",
    "  img = image.load_img(path, target_size=(150,150))\n",
    " \n",
    "  imgplot = plt.imshow(img)\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  images = np.vstack([x])\n",
    " \n",
    "  classes = model.predict(images, batch_size=10)  \n",
    "  print(fn)\n",
    "  if classes==0:\n",
    "   print('messy')\n",
    "  else:\n",
    "   print('clean')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
